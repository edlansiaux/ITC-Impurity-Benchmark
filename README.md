# ITC-Impurity-Benchmark

A comprehensive benchmarking framework for evaluating 23 impurity metrics in decision tree construction, including the novel **ITC (Integrated Tsallis Combination)** metric.

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸ¯ Overview

This repository provides a complete implementation and evaluation of impurity metrics for decision tree learning, with a focus on the **ITC metric** - a novel hybrid approach combining Tsallis entropy with polarization measures.

## ğŸ“Š Key Results

Based on comprehensive benchmarks across 7 datasets with 5 runs each:

### Top 5 Metrics by Average Accuracy

| Rank | Metric | Accuracy | Performance |
|------|--------|----------|-------------|
| ğŸ¥‡ | **Tsallis (Î±=0.5)** | **91.17%** | Best overall |
| ğŸ¥ˆ | **RÃ©nyi (Î±=0.5)** | **90.85%** | Excellent |
| ğŸ¥‰ | **Shannon-Polarization** | **90.64%** | Strong hybrid |
| 4 | Shannon Entropy | 90.57% | Classical baseline |
| 5 | Tsallis (Î±=2.0) / Gini | 90.20% | Traditional methods |

### ITC Performance Highlights

- **ITC (Standard)**: 88.38% accuracy
- **ITC (Î±=1.3)**: 89.16% accuracy  
- **ITC (Î±=1.7)**: 88.59% accuracy
- **Optimal parameters**: Î±=2.0, Î²=4.5, Î³=0.4 (Score: 0.8882)

### Statistical Significance

- **Friedman Test**: Ï‡Â² = 3.89, p-value = 0.692 (no significant global differences)
- **Effect Sizes vs Gini**:
  - Tsallis (Î±=0.5): Cohen's d = 0.458 (small effect)
  - RÃ©nyi (Î±=0.5): Cohen's d = 0.262 (small effect)
  - Shannon-Polarization: Cohen's d = 0.161 (negligible)

## ğŸ—ï¸ Repository Structure

```
ITC-Impurity-Benchmark/
â”œâ”€â”€ data/                  # Dataset loading and management
â”œâ”€â”€ metrics/              # Implementation of all 23 impurity metrics
â”œâ”€â”€ tree/                 # Custom decision tree implementation
â”œâ”€â”€ benchmarks/           # Benchmarking scripts and experiments
â”‚   â”œâ”€â”€ individual_metrics.py
â”‚   â”œâ”€â”€ hybrid_comparison.py
â”‚   â””â”€â”€ sensitivity_analysis.py
â”œâ”€â”€ results/              # Experimental results
â”‚   â”œâ”€â”€ raw_results/     # Detailed per-run results
â”‚   â”œâ”€â”€ tables/          # Aggregated performance tables
â”‚   â””â”€â”€ figures/         # Visualization outputs
â”œâ”€â”€ utils/               # Utilities and visualization tools
â”œâ”€â”€ scripts/             # Utility scripts
â”œâ”€â”€ notebooks/           # Analysis notebooks
â”œâ”€â”€ tests/               # Unit tests
â””â”€â”€ run_all_benchmarks.py  # Main execution script
```

## ğŸ“ˆ Evaluated Metrics

### Classical Metrics
- **Gini Impurity** - Traditional baseline
- **Shannon Entropy** - Information-theoretic approach
- **Misclassification Error** - Simple error-based metric

### Generalized Entropy Measures
- **RÃ©nyi Entropy** (Î±=0.5, 2.0)
- **Tsallis Entropy** (Î±=0.5, 1.3, 2.0)
- **Normalized Tsallis** (Î±=1.3)

### Divergence-Based Metrics
- **Cross Entropy**
- **KL Divergence** (Kullback-Leibler)
- **JS Divergence** (Jensen-Shannon)
- **Bregman Divergence** (squared, entropy)

### Distance-Based Metrics
- **Hellinger Distance**
- **Energy Distance**

### Specialized Metrics
- **Kumaraswamy Distribution**
- **Polarization Index** (Î±=3.5)

### Hybrid Metrics
- **ITC** (Integrated Tsallis Combination)
  - Standard ITC
  - ITC variants (Î±=1.3, 1.7)
- **Shannon-Polarization**
- **Tsallis-Hellinger**

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/edlansiaux/ITC-Impurity-Benchmark.git
cd ITC-Impurity-Benchmark

# Install dependencies
pip install -r requirements.txt
```

### Running Benchmarks

**Full benchmark suite** (all experiments):
```bash
python run_all_benchmarks.py
```

**Individual components**:

```python
# 1. Individual metrics benchmark
from benchmarks.individual_metrics import run_individual_benchmarks
results, aggregated = run_individual_benchmarks()

# 2. Hybrid comparison
from benchmarks.hybrid_comparison import run_hybrid_comparison
hybrid_results = run_hybrid_comparison()

# 3. Sensitivity analysis
from benchmarks.sensitivity_analysis import run_sensitivity_analysis
sensitivity_results = run_sensitivity_analysis()
```

## ğŸ“Š Datasets

The benchmark evaluates metrics on:

### Scikit-learn Datasets
- **Iris** (150 samples, 4 features, 3 classes)
- **Wine** (178 samples, 13 features, 3 classes)
- **Breast Cancer** (569 samples, 30 features, 2 classes)
- **Digits** (1797 samples, 64 features, 10 classes)

### Synthetic Datasets
- **Binary Balanced** (1000 samples, 10 features, 2 classes)
- **Binary Imbalanced** (1000 samples, 10 features, 2 classes, 30:70 ratio)
- **Multiclass** (1500 samples, 12 features, 4 classes)

## ğŸ“‰ Evaluation Metrics

Each impurity metric is evaluated on:

| Metric | Description |
|--------|-------------|
| **Accuracy** | Classification accuracy on test set |
| **Tree Depth** | Average depth of the decision tree |
| **Tree Size** | Total number of nodes |
| **Training Time** | Time to train the model (seconds) |
| **Stability** | Consistency across multiple runs (std dev) |

## ğŸ”¬ Results Details

### Performance by Dataset

Results stored in `results/tables/`:
- `individual_results.csv` - Complete benchmark results
- `hybrid_comparison.csv` - Hybrid metrics comparison
- `statistical_tests.csv` - Statistical significance tests
- `sensitivity_analysis.csv` - Parameter sensitivity results

### Visualizations

Generated figures in `results/figures/`:
- Performance comparison charts
- Parameter sensitivity surfaces
- Statistical analysis plots
- Tree structure visualizations

## ğŸ”§ ITC Metric Details

The **Integrated Tsallis Combination (ITC)** metric is defined as:

```
ITC(p) = Î± Â· Tsallis_q(p) + Î² Â· Polarization(p) + Î³ Â· Balance(p)
```

Where:
- `Tsallis_q(p)` is the Tsallis entropy with parameter q
- `Polarization(p)` measures class separation
- `Balance(p)` encourages balanced splits
- `Î±, Î², Î³` are weighting parameters

**Optimal parameters found**:
- Î± = 2.0 (Tsallis entropy weight)
- Î² = 4.5 (Polarization weight)  
- Î³ = 0.4 (Balance weight)

## ğŸ“š Citation

If you use this code in your research, please cite:

```bibtex
@article{itc2025,
  title={ITC: A Novel Hybrid Impurity Measure for Optimal Decision Tree Construction},
  author={Edouard Lansiaux},
  journal={preprint},
  year={2025}
}
```

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the project
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“§ Contact

**Edouard Lansiaux**

- GitHub: [@edlansiaux](https://github.com/edlansiaux)
- Repository: [ITC-Impurity-Benchmark](https://github.com/edlansiaux/ITC-Impurity-Benchmark)

## ğŸ™ Acknowledgments

- Scikit-learn for providing the base datasets
- NumPy and Pandas communities for excellent scientific computing tools
- All contributors to information theory and decision tree research

---

**Last Updated**: November 1, 2025  
**Benchmark Duration**: ~2h 30min for full suite  
**Python Version**: 3.8+
